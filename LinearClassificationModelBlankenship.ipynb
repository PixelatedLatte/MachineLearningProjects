{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PixelatedLatte/MachineLearningProjects/blob/main/LinearClassificationModelBlankenship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS 460G: Machine Learning\n",
        "## Spring 2026\n",
        "## Assignment 1\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**Double click on this cell and write your name/UK ID/email.**\n",
        "\n",
        "Name:\n",
        "\n",
        "ID:\n",
        "\n",
        "Email:"
      ],
      "metadata": {
        "id": "w8WfAPtgLb0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# READ THIS FIRST\n",
        "\n",
        "## Reminder on what's up for you in this assignment\n",
        "\n",
        "This is one of the three assignments. A maximum of 100 points are available from this assignment. You will need to use your learning from the first 2 weeks' lectures.\n",
        "\n",
        "You will turn in completed version of this notebook (both ipynb and pdf files). Your submission will be graded under 3 major criteria:\n",
        "\n",
        "  * Functional code: Completed code with every piece functional\n",
        "  * Correctness: Your submitted notebook contains correct code that gives accurate results unless otherwise stated\n",
        "  * Documentation: Every cell is well-documented and easy-to-follow to reproduce the results\n",
        "\n",
        "$~$\n",
        "\n",
        "## Reproducibility in iPython Notebooks\n",
        "\n",
        "As you have noticed, iPython notebooks are interactive Python sessions that allow us to spread our code, text, and markdown seamlessly.\n",
        "\n",
        "Every word you read and write is modifiable. You can double click this cell to change the text you're reading now. You will use such cells to write your answers/code.\n",
        "\n",
        "Don't forget to double click the first cell, and write your name, ID, and email.\n",
        "\n",
        "Cells can be added for code or text. Check the top left corner: \"+Code\" to add a new cell for writing code and \"+Text\" to add a new cell for raw texts.\n",
        "\n",
        "The best thing about notebooks is that you can quickly run small components of your code in separate cell to make sure they work before putting together for a larger component. Another good thing is, as you noticed during our in-class hands-on, the entire assignment self-contained in this ipynb file. So, you can put all your functions and classes into the cells of this notebook. Please make sure your code is written cleanly with documentation (how to use your work once completed, to reproduce the exact same results). Once you're done, download the notebook as ipynb file and submit on Canvas before the due date. Please also make sure to download the PDF file when everything works fine: File-->Print-->Save as PDF\n",
        "\n",
        "Please be reminded, it is important to write readable and reproducible code. Let's take a small fine step towards that goal, with this notebook."
      ],
      "metadata": {
        "id": "VPaNH2BJLnjI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4owE5qQVIiq"
      },
      "source": [
        "## **Linear Classification: Data Preparation, Linear Machine Learning Algorithm & Evaluation**\n",
        "\n",
        "---\n",
        "\n",
        "For this experiment, we use Diabetes Screening Dataset from Kaggle. The dataset can be accessed from https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset. There are in total 100,000 samples in the dataset. There are eight different features (age, gender, hypertension,  smoking history, heart_disease, bmi, HbA1c_level, blood_glucose_level) and the corresponding Diabetes label (positive/negative) for each of the samples. These features can be taken as inputs to train a machine learning algorithm to map them to target Diabetes status (0/1) outputs.\n",
        "\n",
        "For simplicity, the non-numeric features (gender and smoking history) have been removed. The modified dataset can be accessed at [diabetes dataset](https://drive.google.com/file/d/1cfc8QVGXdf1EVhW_A_dROHGFmq8n2aTZ/). You should download and upload to your google drive.\n",
        "\n",
        "\n",
        "You need to use the Linear Model (Logistic Regression) discussed in the W2L2 lecture. Then evaluate the model performance using some performance metrics. Please feel free to use any code provided in the *Linear-Classification.ipynb* Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB4DBGed8sOg"
      },
      "source": [
        "### Dataset Preparation (30 points)\n",
        "\n",
        "#### First we load the dataset and try to understand it   \n",
        "\n",
        "#### To Do:\n",
        "\n",
        "<ul>Load the Diabetes dataset from directory</ul>\n",
        "<ul>Get the features and corresponding class labels</ul>\n",
        "<ul>Verify the shape of the features and labels</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, you need to mount google drive for read/write access. Then you can read the CSV file from your drive using Pandas."
      ],
      "metadata": {
        "id": "ieAkqqDaOPq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Mount your google drive directory\n",
        "\n",
        "# https://www.geeksforgeeks.org/data-science/how-to-load-a-dataset-from-the-google-drive-to-google-colab/\n",
        "# ^ Side used for code on how to mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "Ybo3JJEAOKze",
        "outputId": "dd1925b8-37fa-4e80-8d20-b07ddb055ac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gU0oktWmWMk"
      },
      "source": [
        "#Import necessary packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJksLAXSK02n"
      },
      "source": [
        "#### Read the data\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### Understand it: check, analyze, visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ2Ga4Kh8rqk"
      },
      "source": [
        "import pandas as pd\n",
        "#To Do: Use pd.read_csv to read the CSV file from given filepath\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AyAsgqSYrkP"
      },
      "source": [
        "#To Do: Check the keys\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the entire diabetes dataset and check the shape."
      ],
      "metadata": {
        "id": "0pb3sOPSm5Dg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqfd-Q0VBTbT"
      },
      "source": [
        "#To Do: First we extract the 'features' and 'target' from the dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iokCkzKAY704"
      },
      "source": [
        "#To Do: check the shapes of features and labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Display features\n"
      ],
      "metadata": {
        "id": "XW9WSetipG2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Check the label distribution\n"
      ],
      "metadata": {
        "id": "y439BM5uBZFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Do: Double-click on this cell and add your findings on the label distribution from the above cell."
      ],
      "metadata": {
        "id": "mUZT6NWGBgm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's do some plots to better understand the dataset. We can create scatter plot of the dataset by taking any two features at a time (e.g., bmi and HbA1c_level) and see if there is any recognizable pattern."
      ],
      "metadata": {
        "id": "BZAnfm0Tqdig"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuhH4lgwhorr"
      },
      "source": [
        "#To Do: Create a Scatter plot (bmi, HbA1c_level) with the class labels\n",
        "#The plot should be properly annotated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate using any two features (30 points)\n",
        "\n",
        "We can first attempt to build our linear model using any two features to see how the model performs on a test set."
      ],
      "metadata": {
        "id": "598gA69xxTZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Select any two features only, for model training and evaluation\n"
      ],
      "metadata": {
        "id": "jE2dEl08y-59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Verify the shapes\n"
      ],
      "metadata": {
        "id": "2DHNxVBZ7Vvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L92QLuK-Ll4k"
      },
      "source": [
        "#### Split into Training and Testing\n",
        "\n",
        "---\n",
        "\n",
        "#### The general approach to evaulate any machine learning model is to split your data into train and test subsets: former subset is to train and the latter to test the trained model. In a standard split, 75% data are used in training and 25% for testing.\n",
        "\n",
        "#### To Do:\n",
        "<ul>Use the train_test_split function from scikit-learn.model_selection to split into train and test sets.</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWleRfjV_9ON"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#To Do: Split the dataset\n",
        "\n",
        "\n",
        "#To Do: Check the shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Check the label distribution for both train and test sets"
      ],
      "metadata": {
        "id": "FonaXaFiz-nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4rel9JqLvfx"
      },
      "source": [
        "#### Linear Classification Algorithm\n",
        "\n",
        "---\n",
        "\n",
        "#### You can easily get this classifier from scikit-learn. For every classifier model, fit with the training data (features and targets). Then make predictions for the test data (features).\n",
        "\n",
        "#### Obtain the predictions for the following classification algorithms:\n",
        "\n",
        "<li>Linear model: Logistic Regression</li>\n",
        "\n",
        "#### To Do:\n",
        "<ul>Load the classifiers from sklearn</ul>\n",
        "<ul>For every classifier,\n",
        "  <ul>build the model</ul>\n",
        "  <ul>Fit the model with the training data set</ul>\n",
        "  <ul>Make prediction on the test data set</ul>\n",
        "</ul>\n",
        "\n",
        "Check the documentation at\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression for LR for example, and understand different parameters you can pass to the model. Here, we take the default setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHB7VY-XAgzm"
      },
      "source": [
        "#To Do: Load the classifier from scikit-learn and then perform training and testing\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Boundary\n",
        "\n",
        "Since we are dealing with a classification problem containing only 2 features, it is then possible to observe the decision function boundary. The boundary is the rule used by our predictive model to affect a class label given the two feature values of the sample."
      ],
      "metadata": {
        "id": "5UyHgFH0CN1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Display the decision boundary and show train/test data points with class labels"
      ],
      "metadata": {
        "id": "DVw2v3MmBwX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzJhWmLuM9kr"
      },
      "source": [
        "#### Model Evaluation\n",
        "\n",
        "---\n",
        "\n",
        "#### A number of evaluation metrics are available from scikit-learn.metrics that can be used for evaluating the performance of any machine learning model. We will be using the following metrics:\n",
        "* Confusion matrix\n",
        "* F1 Score\n",
        "* ROC curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xLLGXwODwoz"
      },
      "source": [
        "#To Do: Calculate the Confusion matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Calculate F1 score based on the Confusion matrix"
      ],
      "metadata": {
        "id": "ghP2j2yD8oEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Do: Plot the ROC curve with proper annotation"
      ],
      "metadata": {
        "id": "bJKoGcc38vSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate using all six features (30 points)\n",
        "\n",
        "Now let's repeat the above experiment, using all six features instead of two.\n",
        "Except the decision boundary and feature scatter plot, you should repeat all the steps from above in new cells below this."
      ],
      "metadata": {
        "id": "wUSTLcZ39Ez5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance Comparison\n",
        "\n",
        "Finally, compare their performances (2-feature model vs 6-feature model) discussing the calculated metrics."
      ],
      "metadata": {
        "id": "CRxdp5vUZ8Ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use of Generative AI (5 points)\n",
        "\n",
        "**1. Did you get any help from any Generative AI tools (e.g., ChatGPT) for completing this assignment task? Please explain.** (1 points)\n",
        "\n",
        "Your response:\n",
        "\n",
        "$~$\n",
        "\n",
        "\n",
        "**2. What prompts did you use to get assistance from Generative AI? Please list all the prompts that you used.\n",
        "If you didn't get any Generative AI assistance, simply write the following text to respond this question.** (3 points)\n",
        "> **I didn't seek any Generative AI assistance to complete this assignment task.**\n",
        "\n",
        "Your reponse:\n",
        "\n",
        "\n",
        "$~$\n",
        "\n",
        "\n",
        "**3. How would you distribute credit between you and the Generative AI tool? Please give the percentage of your contribution and the contribution of Generative AI.** (1 points)\n",
        "\n",
        "Your reponse:"
      ],
      "metadata": {
        "id": "JuLJ2SXo9q1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion with Others (5 points)\n",
        "\n",
        "**1. Did you have (any level of discussion) with someone else in the class for completing this assignment task? Please explain.** (5 points)\n",
        "\n",
        "Your response:"
      ],
      "metadata": {
        "id": "FP4noDDRYu-_"
      }
    }
  ]
}